{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f429cf21-6190-4198-9b6b-a90a9f36ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import urllib.request\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52f50422-23cf-4546-ab3e-a8088ac4b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize speech recognition and text-to-speech engines\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "def89540-61fc-42b3-9310-5630da17a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ESP32-CAM stream URL and ESP32 control endpoint\n",
    "ESP32_CAM_URL = \"http://172.20.52.94:81/stream\"  # Replace with your ESP32-CAM stream URL\n",
    "ESP32_CONTROL_URL = \"http://172.20.51.59/control\"  # Replace with your ESP32 control endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5836917b-5b65-47e8-baea-10e9a3426323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes\n",
    "CLASSES = [\"Bottle\", \"Cup\", \"Book\", \"Cell phone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d5be8bb-2bbd-44a8-809a-8fc3a8fd5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the custom ResNet-50 model\n",
    "MODEL_PATH = \"fine_tuned_resnet.pth\"  # Replace with your .pth file path\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f971adf7-1e53-413d-bfec-bfa6b9bfea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fc.0.weight', 'fc.0.bias', 'fc.3.weight', 'fc.3.bias']\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "print([key for key in checkpoint.keys() if 'fc' in key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a123bba-6f4c-49c1-a24d-8c90c084dcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ResNet50 model\n",
    "model = models.resnet50(pretrained=False)\n",
    "\n",
    "# Define the FC layer exactly as it was in Colab\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.fc.in_features, 512),  # Matches fc.0.weight and fc.0.bias\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),  # (Optional) Wasn't in your keys but might have been in Colab\n",
    "    torch.nn.Linear(512, len(CLASSES))  # Matches fc.3.weight and fc.3.bias\n",
    ")\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "\n",
    "# Send model to device and set to evaluation mode\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1948d3c4-5e81-4799-88d2-b92fa22ad265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be19dcb8-017f-4828-9c1f-5d8ce9c0f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify an image\n",
    "def classify_image(image):\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return CLASSES[predicted.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84e080ff-a7f6-42d9-916a-b15149341bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "\n",
    "def send_control_command(command):\n",
    "    try:\n",
    "        # Create the JSON payload\n",
    "        data = json.dumps({\"command\": command}).encode(\"utf-8\")\n",
    "        \n",
    "        # Set the headers\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Content-Length\": len(data)\n",
    "        }\n",
    "        \n",
    "        # Create the request\n",
    "        req = urllib.request.Request(ESP32_CONTROL_URL, data=data, headers=headers, method=\"POST\")\n",
    "        \n",
    "        # Send the request\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            response_data = response.read().decode(\"utf-8\")\n",
    "            print(f\"Command sent successfully. Response: {response_data}\")\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(f\"HTTP Error: {e.code} - {e.reason}\")\n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"URL Error: {e.reason}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending command: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3aca889b-d13a-4566-8abb-39c499ab63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A* Path Planning Algorithm\n",
    "def astar_path_planning(start, goal, grid):\n",
    "    def heuristic(a, b):\n",
    "        return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "    open_set = []\n",
    "    heappush(open_set, (0, start))\n",
    "    came_from = {}\n",
    "    g_score = {start: 0}\n",
    "    f_score = {start: heuristic(start, goal)}\n",
    "\n",
    "    while open_set:\n",
    "        _, current = heappop(open_set)\n",
    "\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            return path[::-1]\n",
    "\n",
    "        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "            neighbor = (current[0] + dx, current[1] + dy)\n",
    "            if 0 <= neighbor[0] < len(grid) and 0 <= neighbor[1] < len(grid[0]) and grid[neighbor[0]][neighbor[1]] == 0:\n",
    "                tentative_g_score = g_score[current] + 1\n",
    "                if neighbor not in g_score or tentative_g_score < g_score[neighbor]:\n",
    "                    came_from[neighbor] = current\n",
    "                    g_score[neighbor] = tentative_g_score\n",
    "                    f_score[neighbor] = tentative_g_score + heuristic(neighbor, goal)\n",
    "                    heappush(open_set, (f_score[neighbor], neighbor))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f9d28cd-7b3d-41ea-88ab-a6f754680b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to listen for voice commands\n",
    "def listen_for_command():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening for command...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)  # Adjust for ambient noise\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            command = recognizer.recognize_google(audio).lower()\n",
    "            print(f\"You said: {command}\")\n",
    "            return command\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I could not understand the audio.\")\n",
    "            return None\n",
    "        except sr.RequestError:\n",
    "            print(\"Could not request results from the speech recognition service.\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4e3a2d2-e12b-4429-a69a-d67a024d54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to speak text\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bca476af-d777-4bc0-8d9a-72695814211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_distance():\n",
    "    try:\n",
    "        # Send a GET request to the ESP32 to fetch the distance\n",
    "        response = requests.get(f\"http://172.20.51.59/distance\")\n",
    "        if response.status_code == 200:\n",
    "            distance = float(response.text)  # Assuming the ESP32 returns the distance as a plain text response\n",
    "            return distance\n",
    "        else:\n",
    "            print(f\"Failed to fetch distance. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching distance: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b7d4835-214f-4c40-b04c-2fba86ae95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stream(target_object):\n",
    "    cap = cv2.VideoCapture(ESP32_CAM_URL)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream.\")\n",
    "        return\n",
    "\n",
    "    # Define the desired distance (20 cm)\n",
    "    desired_distance = 20\n",
    "\n",
    "    # Define a simple grid for path planning (adjust based on your environment)\n",
    "    grid = [\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "    ]\n",
    "\n",
    "    start = (0, 0)  # Starting position\n",
    "    goal = (4, 4)   # Goal position (adjust based on your environment)\n",
    "\n",
    "    # Find the path using A* algorithm\n",
    "    path = astar_path_planning(start, goal, grid)\n",
    "    if not path:\n",
    "        speak(\"No path found to the target.\")\n",
    "        return\n",
    "\n",
    "    speak(f\"Searching for the {target_object}.\")\n",
    "    print(f\"Path to follow: {path}\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert frame to PIL image\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Classify the image\n",
    "        predicted_class = classify_image(pil_image)\n",
    "\n",
    "        # Display the frame with the predicted class\n",
    "        cv2.putText(frame, f\"Predicted: {predicted_class}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"ESP32-CAM Stream\", frame)\n",
    "\n",
    "        # Check if the predicted class matches the target object\n",
    "        if predicted_class == target_object:\n",
    "            print(f\"Object found: {target_object}\")\n",
    "            speak(f\"I found the {target_object}.\")\n",
    "            distance = get_distance()  # Get the distance from the object\n",
    "\n",
    "            if distance is not None:\n",
    "                print(f\"Distance to object: {distance} cm\")\n",
    "\n",
    "                if distance <= desired_distance:\n",
    "                    print(f\"Object is close enough. Stopping the vehicle.\")\n",
    "                    send_control_command(\"stop\")  # Stop the vehicle\n",
    "                    cv2.imwrite(f\"{target_object}_captured.jpg\", frame)  # Save the captured image\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Moving forward to get closer to the object.\")\n",
    "                    send_control_command(\"move_forward\")  # Move the vehicle forward\n",
    "            else:\n",
    "                print(\"Failed to retrieve distance. Continuing...\")\n",
    "        else:\n",
    "            # Move along the path\n",
    "            if path:\n",
    "                next_step = path.pop(0)\n",
    "                print(f\"Moving to: {next_step}\")\n",
    "                send_control_command(\"move_forward\")  # Replace with actual movement logic\n",
    "\n",
    "        # Exit on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ded6a6e6-f9ad-4e1d-9784-ce63fe46b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for command...\n",
      "Sorry, I could not understand the audio.\n",
      "Listening for command...\n",
      "You said: find bottle\n",
      "Path to follow: [(0, 1), (0, 2), (0, 3), (0, 4), (1, 4), (2, 4), (3, 4), (4, 4)]\n",
      "Object found: Bottle\n",
      "Distance to object: 142.66 cm\n",
      "Moving forward to get closer to the object.\n",
      "Command sent successfully. Response: Command received: move_forward\n",
      "Object found: Bottle\n",
      "Distance to object: 53.7 cm\n",
      "Moving forward to get closer to the object.\n",
      "Command sent successfully. Response: Command received: move_forward\n",
      "Moving to: (0, 1)\n",
      "Command sent successfully. Response: Command received: move_forward\n",
      "Moving to: (0, 2)\n",
      "Command sent successfully. Response: Command received: move_forward\n",
      "Moving to: (0, 3)\n",
      "Command sent successfully. Response: Command received: move_forward\n",
      "Object found: Bottle\n",
      "Distance to object: 31.87 cm\n",
      "Moving forward to get closer to the object.\n",
      "Command sent successfully. Response: Command received: move_forward\n",
      "Moving to: (0, 4)\n",
      "Command sent successfully. Response: Command received: move_forward\n",
      "Object found: Bottle\n",
      "Distance to object: 32.38 cm\n",
      "Moving forward to get closer to the object.\n",
      "Command sent successfully. Response: Command received: move_forward\n",
      "Object found: Bottle\n",
      "Distance to object: 16.93 cm\n",
      "Object is close enough. Stopping the vehicle.\n",
      "Command sent successfully. Response: Command received: stop\n"
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "if __name__ == \"__main__\":\n",
    "    speak(\"Hello! What object should I find?\")\n",
    "    while True:\n",
    "        command = listen_for_command()\n",
    "        if command:\n",
    "            target_object = None\n",
    "            for obj in CLASSES:\n",
    "                if obj.lower() in command:\n",
    "                    target_object = obj\n",
    "                    break\n",
    "\n",
    "            if target_object:\n",
    "                process_stream(target_object)\n",
    "                break\n",
    "            else:\n",
    "                speak(\"Sorry, I didn't understand. Please try again.\")\n",
    "        else:\n",
    "            speak(\"Sorry, I didn't catch that. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7860766-1eec-45c5-b929-9801048ef42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a488e-477f-4d11-80d5-4e79937c843d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
